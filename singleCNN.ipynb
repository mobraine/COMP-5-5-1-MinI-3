{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8HOra7zSZaC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y29usqULxRIU"
   },
   "outputs": [],
   "source": [
    "#DATASET splitted  \n",
    "allSets = h5py.File('dataset/singleDigits_set.h5','r')\n",
    "print(allSets.keys())\n",
    "train_set = allSets['training_data']\n",
    "train_labels = allSets['training_labels']\n",
    "real_test_set = allSets['test_data']\n",
    "\n",
    "train_set = np.array(train_set)\n",
    "train_labels = np.array(train_labels)\n",
    "real_test_set = np.array(real_test_set)\n",
    "print(\"train_set.shape is \" + str(train_set.shape))\n",
    "print(\"real_test_set.shape is \" + str(real_test_set.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to transform the dataset into a Tensor, how??? first transform images into array\n",
    "train_set = np.asarray(train_set)\n",
    "print(train_set.shape)\n",
    "#print(train_set[0])\n",
    "print(train_labels.shape)\n",
    "#after split there are 167339 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "\n",
    "    cv = KFold(n_splits=10)\n",
    "    count = 1\n",
    "    for train_index, test_index in cv.split(train_set): # Run 5 times\n",
    "        count += 1\n",
    "        x, x_test, y, y_test = train_set[train_index], train_set[test_index], train_labels[train_index], train_labels[test_index]\n",
    "        if(count==5):#Which segment you choose\n",
    "            break\n",
    "    print(\"x.shape = \" + str(x.shape))\n",
    "    print(\"y.shape = \" + str(y.shape))\n",
    "    \n",
    "    y = y.reshape(1,-1)\n",
    "    y_test = y_test.reshape(1, -1)\n",
    "    y = np.squeeze(y)\n",
    "    y = pd.Series(y)\n",
    "    y = pd.get_dummies(y)\n",
    "    y = np.array(y).T\n",
    "    y_test = np.squeeze(y_test)  \n",
    "    y_test = pd.Series(y_test)\n",
    "    y_test = pd.get_dummies(y_test)\n",
    "    y_test = np.array(y_test).T  \n",
    "\n",
    "    return x,y,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    return (np.exp(z)-np.exp(-z))/(np.exp(z)+np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "def tanh_1(z):\n",
    "    return 1-tanh(z)**2\n",
    "\n",
    "def relu_1(z):\n",
    "    return np.maximum(0, z/np.abs(z))\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b, layer, m, lm, sigma2, mu):\n",
    "    answers = forward_test_predict(w, b, x, layer, m, lm, sigma2, mu)\n",
    "    answers = answers.T\n",
    "    for i in range(x.shape[1]):\n",
    "        answers[i] = np.where(answers[i].max() == answers[i], 1, 0)\n",
    "\n",
    "    print(answers.shape)\n",
    "    result = np.argmax(answers, axis = 1)\n",
    "    print(\"y_test_label is \" + str(result))\n",
    "    return result\n",
    "\n",
    "def initialize(layer, n, m, hidden):\n",
    "    np.random.seed(1)\n",
    "    Vdw, Vdb, Sdw, Sdb = [],[],[],[]#refresh all\n",
    "    b = []\n",
    "    w = []\n",
    "    \n",
    "    for i in range(0, layer):\n",
    "        if i != 0 and i != layer - 1:\n",
    "            t0 = np.random.randn(hidden, hidden) * np.sqrt(2 / hidden)\n",
    "        elif i == 0:\n",
    "            t0 = np.random.randn(hidden, m) * np.sqrt(2 / m)\n",
    "        else:                   \n",
    "            t0 = np.random.randn(10, hidden) * np.sqrt(2 / hidden)\n",
    "        w.append(t0)\n",
    "        b.append(1)\n",
    "        Vdw.append(0)\n",
    "        Vdb.append(0)\n",
    "        Sdw.append(0)\n",
    "        Sdb.append(0)\n",
    "\n",
    "    return w, b, Vdw, Vdb, Sdw, Sdb\n",
    "\n",
    "smallNumber = 0.000000000001\n",
    "sm = smallNumber\n",
    "\n",
    "def printAccuracy(x, y, w, b, layer, m, lm, sigma2, mu):\n",
    "    temp0 = forward_test(w, b, x, y, layer, m, lm, sigma2, mu)\n",
    "    temp0 = temp0.T\n",
    "    \n",
    "    for i in range(x.shape[1]):\n",
    "        temp0[i] = np.where(temp0[i].max() == temp0[i], 1, 0)\n",
    "        \n",
    "    temp0 = temp0.T \n",
    "    classes = np.unique(y) \n",
    "    \n",
    "    temp1 = np.sum(np.abs(y - temp0), axis = 0, keepdims=True)/2\n",
    "    temp2 = 1-np.sum(temp1, axis=1, keepdims=True)/10000\n",
    "    temp2 = np.squeeze(temp2)\n",
    "\n",
    "    print(\"Accuracy: {0}%\".format(temp2 * 100)) #100%\n",
    "    return 0\n",
    "\n",
    "\n",
    "'''\n",
    "Reference: \n",
    "Realize mnist handwritten digit recognition with python's numpy\n",
    "https://www.programmersought.com/article/38914943265/\n",
    "We understood it and rewrite these mothods below\n",
    "'''\n",
    "\n",
    "\n",
    "def forward_back(w, b, a, Y, layer, m, lm):\n",
    "    z = []\n",
    "    add = 0\n",
    "    sigma2,mu = [],[]\n",
    "    \n",
    "    for i in range(0, layer):\n",
    "        zl = np.dot(w[i], a) + b[i]\n",
    "\n",
    "        multiplex = (1/m)*np.sum(zl, axis=1, keepdims = True)\n",
    "        sigmaL = (1/m)*np.sum(np.power(zl - multiplex,2),axis=1,keepdims=True)\n",
    "        \n",
    "        z_norm = (zl - multiplex)/(np.sqrt(sigmaL + sm))\n",
    "        gamma, beta_1 = 1*np.sqrt(sigmaL + sm), multiplex+0\n",
    "        \n",
    "        zl = np.multiply(z_norm,gamma) + beta_1\n",
    "        mu.append(multiplex)\n",
    "        sigma2.append(sigmaL)\n",
    "\n",
    "        add += np.sum((lm / (2 * m)) * np.dot(w[i], w[i].T))\n",
    "        z.append(zl)\n",
    "        a = relu(zl)\n",
    "\n",
    "    t = np.exp(zl)\n",
    "    ti = np.sum(t,axis = 0,keepdims=True)\n",
    "    \n",
    "    a = np.divide(t,ti)\n",
    "    J = (-1/m)*np.sum(Y*np.log(a))+ add \n",
    "\n",
    "    return z, a, J,sigma2,mu\n",
    "\n",
    "def forward_test(w, b, a, Y, layer, m, lm,sigma2,mu): \n",
    "    for i in range(0, layer):\n",
    "        zl = np.dot(w[i], a) + b[i]\n",
    "\n",
    "        z_norm = (zl - mu[i]) / (np.sqrt(sigma2[i] + sm))\n",
    "        gamma, beta_1 = 1 * np.sqrt(sigma2[i] + sm), mu[i] + 0 \n",
    "        \n",
    "        zl = np.multiply(z_norm, gamma) + beta_1\n",
    "        a = relu(zl)\n",
    "        \n",
    "    t = np.exp(zl)\n",
    "    ti = np.sum(t, axis=0, keepdims=True) \n",
    "    a = np.divide(t, ti)  \n",
    "    return a\n",
    "\n",
    "def forward_test_predict(w, b, a, layer, m, lm,sigma2,mu):  \n",
    "    for i in range(0, layer):\n",
    "        zl = np.dot(w[i], a) + b[i]\n",
    "\n",
    "        z_norm = (zl - mu[i]) / (np.sqrt(sigma2[i] + sm))\n",
    "        gamma, beta_1 = 1 * np.sqrt(sigma2[i] + sm), mu[i] + 0 \n",
    "        \n",
    "        zl = np.multiply(z_norm, gamma) + beta_1\n",
    "        a = relu(zl)\n",
    "\n",
    "    t = np.exp(zl)\n",
    "    ti = np.sum(t, axis=0, keepdims=True) \n",
    "    \n",
    "    a = np.divide(t, ti) \n",
    "    return a\n",
    "\n",
    "def backward(w, b, X, Y, m, layer, lm):\n",
    "    z,a,J,sigma2,mu = forward_back(w,b,X,Y,layer,m,lm)\n",
    "    \n",
    "    dw,db = [],[]\n",
    "    for i in range(layer - 1, 0, -1):\n",
    "        if i == layer - 1:\n",
    "            dz = a - Y\n",
    "        else:\n",
    "            dz = np.dot(w[i + 1].T, dz) * relu_1(z[i])\n",
    "            \n",
    "        Dw = 1 / m * (np.dot(dz, relu(z[i - 1]).T)) + (lm / m) * w[i]\n",
    "        Db = 1 / m * np.sum(dz, axis=1, keepdims=True)\n",
    "        \n",
    "        dw.append(Dw)\n",
    "        db.append(Db)\n",
    "\n",
    "    dz = np.dot(w[1].T, dz) * relu_1(z[0])\n",
    "    Dw = 1 / m * np.dot(dz, X.T) + (lm / m) * w[0]\n",
    "    \n",
    "    Db = 1 / m * np.sum(dz, axis=1, keepdims = True)\n",
    "    \n",
    "    dw.append(Dw)\n",
    "    db.append(Db)\n",
    "    return dw, db, J,sigma2,mu\n",
    "\n",
    "def back_momentum(w, b, X, Y, learning, m, layer, lm, beta, Vdw, Vdb):\n",
    "    dw, db, J,sigma2,mu = backward(w,b,X,Y,m,L,lm)\n",
    "    \n",
    "    for i in range(0, layer):\n",
    "        Vdw[i] = beta * Vdw[i] + (1 - beta) * dw[L-i-1]\n",
    "        Vdb[i] = beta * Vdb[i] + (1 - beta) * db[L-i-1]\n",
    "        \n",
    "        w[i] = w[i] - learning * Vdw[i]\n",
    "        b[i] = b[i] - learning * Vdb[i]\n",
    "        \n",
    "    return w,b,J,Vdw,Vdb,sigma2,mu\n",
    "\n",
    "def back_RMSprop(w, b, X, Y, learning, m, layer, lm, beta, Sdw, Sdb):\n",
    "    dw, db, J ,sigma2,mu= backward(w,b,X,Y,m,L,lm) \n",
    "    \n",
    "    for i in range(0, layer):\n",
    "        Sdw[i] = beta * Sdw[i] + (1 - beta) * np.power(dw[L-i-1],2)\n",
    "        Sdb[i] = beta * Sdb[i] + (1 - beta) * np.power(db[L-i-1],2)\n",
    "        \n",
    "        w[i] = w[i] - learning * dw[L-i-1] / (np.power(Sdw[i],1/2) + sm)\n",
    "        b[i] = b[i] - learning * db[L-i-1] / (np.power(Sdb[i],1/2) + sm)\n",
    "        \n",
    "    return w,b,J,Sdw,Sdb,sigma2,mu\n",
    "\n",
    "def back_Adam(w, b, X, Y, learning, m, layer, lm, beta, Vdw, Vdb, Sdw, Sdb):\n",
    "    dw, db, J ,sigma2,mu= backward(w, b, X, Y, m, layer, lm)\n",
    "    for i in range(0, layer):\n",
    "        Vdw[i] = beta * Vdw[i] + (1 - beta) * dw[layer - i - 1]\n",
    "        Vdb[i] = beta * Vdb[i] + (1 - beta) * db[layer - i - 1]\n",
    "        \n",
    "        Sdw[i] = beta * Sdw[i] + (1 - beta) * np.power(dw[layer-i-1],2)\n",
    "        Sdb[i] = beta * Sdb[i] + (1 - beta) * np.power(db[layer-i-1],2)\n",
    "        \n",
    "        w[i] = w[i] - learning * Vdw[i] / (np.power(Sdw[i],1/2) + sm)\n",
    "        b[i] = b[i] - learning * Vdb[i] / (np.power(Sdb[i],1/2) + sm)\n",
    "        \n",
    "    return w,b,J,Vdw,Vdb,Sdw,Sdb,sigma2,mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    loss_history= []\n",
    "    \n",
    "    layer = 5\n",
    "    hidden = 512\n",
    "    lr = 0.005\n",
    "    decay_rate = 0.0009\n",
    "    \n",
    "    \n",
    "    lambd = 0.01 \n",
    "    beta = 0.9\n",
    "    mb = 1000\n",
    "    sigma2 = 1\n",
    "    mu = 1\n",
    "    \n",
    "    train_set_x_raw, train_set_y, test_set_x_raw, test_set_y = load_dataset()\n",
    "    \n",
    "    train_set_x = train_set_x_raw.reshape((train_set_x_raw.shape[0], -1)).T / 255  \n",
    "    \n",
    "    test_set_x = test_set_x_raw.reshape((test_set_x_raw.shape[0], -1)).T / 255  \n",
    "    \n",
    "    real_test_set_dim = real_test_set.reshape((real_test_set.shape[0], -1)).T / 255  \n",
    "    \n",
    "    print(\"train_set_x.shape is \" + str(train_set_x.shape))\n",
    "    print(\"train_set_y.shape is \" + str(train_set_y.shape))\n",
    "    print(\"test_set_x.shape is \" + str(test_set_x.shape))\n",
    "    print(\"test_set_y.shape is \" + str(test_set_y.shape))\n",
    "    \n",
    "    w,b,Vdw,Vdb,Sdw,Sdb = initialize(layer, train_set_x.shape[1], train_set_x.shape[0], hidden)\n",
    "    for i in range(0,161): #Number of iterations. Our best case is 161 times.\n",
    "        Sigma2, Mu,J_average = 0,0,0\n",
    "        for j in range(0,(train_set_x.shape[1] // mb)):\n",
    "            w,b,J,Vdw,Vdb,Sdw,Sdb,sigma2,mu = back_Adam(w,b,((train_set_x.T)[j*mb:(j+1)*mb]).T,((train_set_y.T)[j*mb:(j+1)*mb]).T,lr,mb,layer,lambd,beta,Vdw,Vdb, Sdw, Sdb)\n",
    "            \n",
    "            Sigma2 = np.multiply(beta, Sigma2) + np.multiply((1-beta), sigma2)\n",
    "            Mu = np.multiply(beta, Mu) + np.multiply((1 - beta), mu)\n",
    "            \n",
    "            J_average = np.multiply(beta,J) + np.multiply((1-beta), J)\n",
    "            \n",
    "        lr = lr * (1 / (1 + i*decay_rate) )\n",
    "        \n",
    "        if i % 1 == 0: #Print step by step\n",
    "            print(\"lossï¼š\",J_average)\n",
    "            loss_history.append(J_average)\n",
    "            printAccuracy(test_set_x,test_set_y,w,b,layer,test_set_x.shape[1],lambd,Sigma2,Mu)\n",
    "            \n",
    "    plt.plot(loss_history)\n",
    "    plt.show()\n",
    "\n",
    "    printAccuracy(test_set_x,test_set_y,w,b,L,test_set_x.shape[1],lambd,Sigma2,Mu)\n",
    "    print(\"test_set_x.shape\" + str(test_set_x.shape))\n",
    "    print(\"test_set_y.shape\" + str(test_set_y.shape))\n",
    "    singleAnswers = predict(real_test_set_dim,w,b,L,test_set_x.shape[1],lambd,Sigma2,Mu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(singleAnswers).to_csv(\"generatedAnswers/singleAnswers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Index\n",
    "test_set_index = h5py.File('dataset/test_set_index.h5','r')\n",
    "print(test_set_index.keys())\n",
    "set_index = test_set_index['test_set_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final answer\n",
    "finalAnswer = []\n",
    "number_of_test = 0\n",
    "temp = []\n",
    "for i in range(len(set_index)):\n",
    "    if(set_index[i]!=0):\n",
    "        temp.append(singleAnswers[i])\n",
    "    else:\n",
    "        while(len(temp)<5):\n",
    "            temp.append(10)\n",
    "        if(i != 0):\n",
    "            finalAnswer.append(temp)\n",
    "        number_of_test += 1\n",
    "        temp = []\n",
    "        temp.append(singleAnswers[i])\n",
    "finalAnswer.append(temp)\n",
    "print(len(finalAnswer))\n",
    "#finalAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate result file\n",
    "import csv\n",
    "with open(\"generatedAnswers/finalResult.csv\", 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    count = 0\n",
    "    writer.writerow([\"Id\"]+[\"Label\"])\n",
    "    for row in finalAnswer:\n",
    "        string = str(row)\n",
    "        #writer.writerow(str(count) + str(row[0]).replace(',','') + str(row[1]) + str(row[2]) + str(row[3]) + str(row[4]))\n",
    "        string = string.replace(' ', '').replace(',', '').strip('[').strip(']')\n",
    "        writer.writerow([str(count)]+[string])\n",
    "        count += 1\n",
    "    #writer.writerows(finalAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP 551 Mini Project 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
